<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>개발새발 블로그</title>
    <description>Python, Django, React 등 이런저런 개발 그리고 잡다한 생각을 적을거에요.</description>
    <link>https://l0o02.github.io/</link>
    <atom:link href="https://l0o02.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 06 May 2019 13:21:06 +0000</pubDate>
    <lastBuildDate>Mon, 06 May 2019 13:21:06 +0000</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>군대에서 코딩하는 방법</title>
        <description>&lt;h2 id=&quot;군대에서-코딩하기&quot;&gt;군대에서 코딩하기&lt;/h2&gt;
</description>
        <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2019/05/06/coding-army-1/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2019/05/06/coding-army-1/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>파이썬만으로 간단하게 HTTP 서버 열기</title>
        <description>&lt;h2 id=&quot;python으로-간단한-웹-서버-만들기&quot;&gt;Python으로 간단한 웹 서버 만들기&lt;/h2&gt;

&lt;p&gt;Apache를 설치하기 힘든 환경일 때나, 웹 디자인을 공부할 때 용이하다. 사용 방법은 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt;가 있는 루트 디렉토리로 가서 아래 명령어를 실행하면 된다.
뒤에 숫자는 포트이다.&lt;/p&gt;
&lt;center&gt;
`python 2.X` 버전

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; SimpleHTTPServer 8000&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

`python 3.X` 버전

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;python3 &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; http.server 8000&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/42408605-5ebf682c-8209-11e8-9e37-8b6ff2c63124.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/07/07/how-to-run-a-server-with-python/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/07/07/how-to-run-a-server-with-python/</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>웹 페이지에 맨 위로 이동하는 버튼을 만들어주는 라이브러리</title>
        <description>&lt;h2 id=&quot;vanilla-back-to-top&quot;&gt;Vanilla Back To Top&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41758958-bb7ace2e-7626-11e8-8138-5c54de288165.png&quot; alt=&quot;image&quot; /&gt;
&lt;a href=&quot;https://www.npmjs.com/package/vanilla-back-to-top&quot;&gt;이동하기&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/22/html-back-to-top/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/22/html-back-to-top/</guid>
        
        
        <category>library</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#scrapy-란&quot; id=&quot;markdown-toc-scrapy-란&quot;&gt;Scrapy 란?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scrapy-첫-코드-작성하기&quot; id=&quot;markdown-toc-scrapy-첫-코드-작성하기&quot;&gt;Scrapy 첫 코드 작성하기&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#설치하기&quot; id=&quot;markdown-toc-설치하기&quot;&gt;설치하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#scrapy-shell-사용해보기&quot; id=&quot;markdown-toc-scrapy-shell-사용해보기&quot;&gt;Scrapy Shell 사용해보기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#제목&quot; id=&quot;markdown-toc-제목&quot;&gt;제목&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#올린-뉴스-사이트&quot; id=&quot;markdown-toc-올린-뉴스-사이트&quot;&gt;올린 뉴스 사이트&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#미리보기&quot; id=&quot;markdown-toc-미리보기&quot;&gt;미리보기&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spider-작성하기&quot; id=&quot;markdown-toc-spider-작성하기&quot;&gt;Spider 작성하기&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#hello-scrapy-world&quot; id=&quot;markdown-toc-hello-scrapy-world&quot;&gt;Hello Scrapy World!&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spider-생성하기&quot; id=&quot;markdown-toc-spider-생성하기&quot;&gt;Spider 생성하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spider-실행하고-결과-확인하기&quot; id=&quot;markdown-toc-spider-실행하고-결과-확인하기&quot;&gt;Spider 실행하고 결과 확인하기&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#csv로-내보내기&quot; id=&quot;markdown-toc-csv로-내보내기&quot;&gt;CSV로 내보내기&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;scrapy-란&quot;&gt;Scrapy 란?&lt;/h2&gt;
&lt;p&gt;최근 웹에는 수억개의 웹페이지가 있으며, 대부분의 페이지들은 수많은 정보를 가지고 있습니다. 최근 빅데이터가 대두되면서 이전에 작성되었던 페이지들의 정보를 모아 유의미한 정보를 도출하기 위한 여러가지 방법들이 논의되고 있고, 이를 Scraping(혹은 Crawling)이라고 합니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Scrapy&lt;/code&gt;는 Scraping을 도와주기위한 파이썬 기반 라이브러리입니다. Scrapy를 이용하여 필요한 페이지로 접속하여 원하는 형태로 데이터를 가공하여 데이터를 저장할수 있도록 도와줍니다. &lt;a href=&quot;http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC/Scrapy#h_a103e753e7b14159b61f918a62b1a4c5&quot;&gt;(출처)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;scrapy-첫-코드-작성하기&quot;&gt;Scrapy 첫 코드 작성하기&lt;/h2&gt;
&lt;h4 id=&quot;설치하기&quot;&gt;설치하기&lt;/h4&gt;
&lt;p&gt;터미널에 아래 명령어를 입력해 &lt;code class=&quot;highlighter-rouge&quot;&gt;Scrapy&lt;/code&gt;를 설치합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;scrapy&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;scrapy-shell-사용해보기&quot;&gt;Scrapy Shell 사용해보기&lt;/h4&gt;
&lt;p&gt;Scrapy Shell을 사용함으로써, 프로젝트를 생성하지 않고 간단하게 Scrapy를 체험할 수 있습니다. 아래 명령어를 입력해서 Shell을 실행시킵니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scrapy shell&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;http://news.naver.com/main/list.nhn?mode=LSD&amp;amp;mid=sec&amp;amp;sid1=001&quot;&gt;네이버 뉴스 페이지&lt;/a&gt;를 크롤링하려고 합니다. Scrapy 크롤러는 &lt;code class=&quot;highlighter-rouge&quot;&gt;starting point&lt;/code&gt;를 필요로 합니다. 말 그대로, 크롤링을 시작할 위치를 정하는 겁니다. 
아래 명령어를 통해 Starting Point를 설정합시다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'http://news.naver.com/main/list.nhn?mode=LSD&amp;amp;mid=sec&amp;amp;sid1=001'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;그럼, &lt;a href=&quot;https://ko.wikipedia.org/wiki/HTTP_%EC%83%81%ED%83%9C_%EC%BD%94%EB%93%9C&quot;&gt;Response Code&lt;/a&gt;가 출력됩니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41637651-ef34b3a8-748f-11e8-9bcc-e4c4e1fadd78.png&quot; alt=&quot;image&quot; /&gt;
이제 크롤러가 무엇을 다운로드했는지 확인해봅시다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;이 명령어는 크롤러가 다운로드한 페이지를 기본 브라우저를 통해 실행합니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41637767-863f6f04-7490-11e8-981f-7b06810d10e3.png&quot; alt=&quot;image&quot; /&gt;
경로를 보면 아시겠지만, 로컬에 저장이 됬습니다. 이제 소스를 확인해볼겁니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;다운로드 된, 웹 사이트의 소스가 출력됩니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41637816-d7a9ecfc-7490-11e8-81a0-929fc60d8fb7.png&quot; alt=&quot;image&quot; /&gt;
오늘 크롤링 할 것은 세 가지 입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;제목&lt;/li&gt;
  &lt;li&gt;올린 뉴스 사이트&lt;/li&gt;
  &lt;li&gt;미리보기&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;제목&quot;&gt;제목&lt;/h4&gt;
&lt;p&gt;그러면 제목을 먼저 크롤링 해보겠습니다. 개발자 도구에 들어가서 제목 부분의 &lt;code class=&quot;highlighter-rouge&quot;&gt;XPath&lt;/code&gt;를 복사합니다. 두번째 뉴스의 XPath와 맨 아랫줄에있는 뉴스의 XPath도 비교해봅니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;첫번째 뉴스 : //*[@id=”main_content”]/div[2]/ul[1]/li[1]/dl/dt[2]/a&lt;/li&gt;
  &lt;li&gt;두번째 뉴스 : //*[@id=”main_content”]/div[2]/ul[1]/li[2]/dl/dt[2]/a&lt;/li&gt;
  &lt;li&gt;마지막 뉴스 : //*[@id=”main_content”]/div[2]/ul[2]/li[10]/dl/dt[2]/a&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;여기서 어떤 정보를 얻을 수 있을까요?&lt;br /&gt;&lt;br /&gt;
첫번째로는, 포스트는 &lt;code class=&quot;highlighter-rouge&quot;&gt;li[1]~li[10]&lt;/code&gt;로 구성됬다는 것 입니다.&lt;br /&gt;
두번째로는, ul로 &lt;code class=&quot;highlighter-rouge&quot;&gt;두 파트&lt;/code&gt;가 나뉜다는 것 입니다. &lt;em&gt;아래 사진 참고.&lt;/em&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41638191-08538ef6-7493-11e8-808e-9f0dc4bc541d.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결국 모든 포스트를 list에 저장하기 위해서는 태그[숫자]의 숫자 부분을 삭제해주면 됩니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;//*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;main_content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ul&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;XPath를 얻었으니 이제 크롤링을 해봅니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'//*[@id=&quot;main_content&quot;]/div[2]/ul/li/dl/dt[2]/a/text()'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41638554-f403c9be-7494-11e8-9911-afc5729e7de0.png&quot; alt=&quot;image&quot; /&gt;
포스트 제목들이 출력됩니다. \n\t\r 이 지저분해 보이지만, 이 부분은 다음에 Project를 생성하고 CSV를 만들어 내보낼 때 제거하도록 합시다.&lt;/p&gt;
&lt;h4 id=&quot;올린-뉴스-사이트&quot;&gt;올린 뉴스 사이트&lt;/h4&gt;
&lt;p&gt;올린 뉴스 사이트는 CSS Selector를 통해 크롤링 했습니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.writing::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;뉴스 회사들이 출력되는게 보일겁니다.&lt;/p&gt;
&lt;h4 id=&quot;미리보기&quot;&gt;미리보기&lt;/h4&gt;
&lt;p&gt;미리보기도 마찬가지로 CSS Selector를 통해 크롤링 했습니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.lede::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;계속 CSS Selector인 Class로 크롤링 하는 이유는 .writing이나 .lede같은 의미가 있는 Class들은 대체로 같은 요소에만 쓰입니다. 꼭 그런것만은 아니니 결과를 꼭 확인해 봐야 합니다. 확인해 봤을 때 같은 요소에서만 쓰인다면, 훨씬 간결하고 유연한 코드를 완성할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;spider-작성하기&quot;&gt;Spider 작성하기&lt;/h2&gt;
&lt;p&gt;기본적인 scrapy 프로젝트의 구조는 이렇습니다. 참고하고 프로젝트를 만들어봅시다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41639378-76caee9c-7498-11e8-8499-480f2b8c34bc.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;hello-scrapy-world&quot;&gt;Hello Scrapy World!&lt;/h4&gt;
&lt;p&gt;아래 명령어를 통해 &lt;code class=&quot;highlighter-rouge&quot;&gt;scrapy project&lt;/code&gt;를 생성해줍니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scrapy startproject naverscraper&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;그리고 프로젝트 안에 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;spiders&lt;/code&gt;폴더에 들어갑니다.&lt;/p&gt;
&lt;center&gt;
&lt;script src=&quot;https://asciinema.org/a/Ix2l2BBFNMq08ajIueRefzaan.js&quot; id=&quot;asciicast-Ix2l2BBFNMq08ajIueRefzaan&quot; async=&quot;&quot;&gt;&lt;/script&gt;
&lt;/center&gt;

&lt;h4 id=&quot;spider-생성하기&quot;&gt;Spider 생성하기&lt;/h4&gt;
&lt;p&gt;genspider 명령어를 통해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;newsbot&lt;/code&gt;을 생성합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scrapy genspider newsbot news.naver.com/main/list.nhn?mode&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;LSD&amp;amp;mid&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;sec&amp;amp;sid1&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;001&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;생성된 &lt;code class=&quot;highlighter-rouge&quot;&gt;newsbot.py&lt;/code&gt; 에 소스를 입력합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scrapy&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NewsbotSpider&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scrapy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spider&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'newsbot'&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;start_urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'http://news.naver.com/main/list.nhn?mode=LSD&amp;amp;mid=sec&amp;amp;sid1=001'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'//*[@id=&quot;main_content&quot;]/div[2]/ul/li/dl/dt[2]/a/text()'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;authors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.writing::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;previews&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.lede::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;authors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;previews&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;scraped_info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'title'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'author'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'preview'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraped_info&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;sup style=&quot;color: #878787;&quot;&gt;
8~10: 크롤링 한 데이터를 list로 저장&lt;br /&gt;
12: zip 함수는 아래 사진 참고&lt;br /&gt;
13: scraped_info 에 zip으로 slice 한 데이터들을 저장&lt;br /&gt;
14~16: strip 함수를 이용해 문자열에 필요없는 공백을 제거&lt;br /&gt;
&lt;/sup&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41640142-a3ddbef2-749b-11e8-9e73-43fc69118fb2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;spider-실행하고-결과-확인하기&quot;&gt;Spider 실행하고 결과 확인하기&lt;/h4&gt;
&lt;p&gt;newsbot을 실행시켜봅니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scrapy crawl newsbot&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41640256-0ba7dc20-749c-11e8-8b24-8bb077b558f0.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;csv로-내보내기&quot;&gt;CSV로 내보내기&lt;/h2&gt;
&lt;p&gt;프로젝트 폴더에있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;settings.py&lt;/code&gt;에 입력합니다:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;FEED_FORMAT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;csv&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FEED_URI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;naver_news.csv&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;그리고 다시 Spider을 실행합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scrapy crawl newsbot&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;그럼 같은 디렉토리에 뉴스 내용들이 크롤링되어 csv에 저장됩니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41640344-64582b7c-749c-11e8-9510-b57a0356ec58.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;최종 소스 :&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;newsbot.py&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scrapy&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NewsbotSpider&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scrapy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spider&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'newsbot'&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;start_urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'http://news.naver.com/main/list.nhn?mode=LSD&amp;amp;mid=sec&amp;amp;sid1=001'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'//*[@id=&quot;main_content&quot;]/div[2]/ul/li/dl/dt[2]/a/text()'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;authors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.writing::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;previews&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;css&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.lede::text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;authors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;previews&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;scraped_info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'title'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'author'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;'preview'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraped_info&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;수고하셨습니다, 이것으로 scrapy의 기본적인 사용방법에 대해 알아봤습니다.&lt;/p&gt;
</description>
        <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/19/python-scrapy-1/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/19/python-scrapy-1/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 7 : Scrapy 란? Scrapy VS Beautiful Soup</title>
        <description>&lt;h2 id=&quot;scrapy-vs-beautiful-soup&quot;&gt;Scrapy VS Beautiful Soup&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;이전까지 튜토리얼로 배워왔던 Beautiful Soup 와 생소한 Scrapy 의 장단점을 정리해보려고 합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;beautiful-soup-란&quot;&gt;Beautiful Soup 란?&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Beautiful Soup&lt;/code&gt;는 웹 상의 가치있는 정보를 빠르게 크롤링 하기위한 도구입니다. 진입 장벽이 매우 낮고 간결해서, 입문 개발자에게 안성맞춤입니다. 그리고
이 라이브러리는, 스스로 웹 사이트를 크롤링 할 수 없습니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;urlib2&lt;/code&gt; 와 &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt;로 HTML 소스를 가져와야만 합니다.&lt;/p&gt;

&lt;h4 id=&quot;scrapy-란&quot;&gt;Scrapy 란?&lt;/h4&gt;
&lt;p&gt;Scrapy 는 파이썬으로 작성되었으며, &lt;code class=&quot;highlighter-rouge&quot;&gt;spider&lt;/code&gt;를 작성해서 크롤링을 합니다. Scrapy 에서는 직접 &lt;code class=&quot;highlighter-rouge&quot;&gt;Beautiful Soup&lt;/code&gt; 나 &lt;code class=&quot;highlighter-rouge&quot;&gt;lxml&lt;/code&gt;을 사용할 수 있습니다. 하지만 Beautiful Soup 에서는 지원하지 않는 &lt;code class=&quot;highlighter-rouge&quot;&gt;XPath&lt;/code&gt;를 Scrapy에서는 사용할 수 있습니다. XPath 를 사용함으로써 복잡한 HTML소스를 쉽게 크롤링 할 수 있게 해줍니다.&lt;/p&gt;

&lt;h4 id=&quot;어떤게-더-좋을까&quot;&gt;어떤게 더 좋을까?&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Beautiful Soup&lt;/code&gt;는 오로지 HTML을 파싱하고 데이터를 크롤링하는데에만 쓰입니다. 반면에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Scrapy&lt;/code&gt;는 HTML을 다운로드하고 데이터에 접근하여 저장합니다. 만약 이 두가지중에 선택해야 한다면, 아래 표를 참고하시는게 도움이 될겁니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Framework&lt;/th&gt;
      &lt;th&gt;Beautiful Soup&lt;/th&gt;
      &lt;th&gt;Scrapy&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;진입장벽&lt;/td&gt;
      &lt;td&gt;매우 쉽다.&lt;/td&gt;
      &lt;td&gt;난해하다, 하지만 &lt;a href=&quot;https://doc.scrapy.org/en/1.5/intro/tutorial.html&quot;&gt;Scrapy 문서&lt;/a&gt;를 참고해서 따라해보면 생각보다는 괜찮다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;자료량&lt;/td&gt;
      &lt;td&gt;많이 부족한 편이다.&lt;/td&gt;
      &lt;td&gt;매우 많은 프로젝트와 플러그인이 존재한다. Stack OverFlow 에도 많은 케이스가 존재한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;확장성&lt;/td&gt;
      &lt;td&gt;확장하기가 쉽지는 않다.&lt;/td&gt;
      &lt;td&gt;쉽게 middleware 를 커스터마이징 할 수 있다. 유지가 쉬운 편이다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;퍼포먼스&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;multiprocessing&lt;/code&gt;을 하면 매우 빠르다.&lt;/td&gt;
      &lt;td&gt;괜찮은 편이다. 웹 페이지를 짧은 시간내에 크롤링할 수 있다. 잦은 경우로 download_delay 를 설정해줘야 spider가 정지당하는 경우를 피할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;가볍고 빠른 Beautiful Soup 와 자료가 방대하고 유연한 Scrapy 를 상황에 맞게 잘 골라 쓰면 되겠습니다.&lt;/p&gt;
</description>
        <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/15/python-crawling-scrapy/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/15/python-crawling-scrapy/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 6 : Pagination 된 게시판 크롤링</title>
        <description>&lt;h2 id=&quot;pagination-된-글-크롤링-하기&quot;&gt;Pagination 된 글 크롤링 하기&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Pagination 이란, 여러 페이지에 일련의 관련 콘텐츠가 있음을 나타내는 페이지 번호 매김을 보여주는 것 입니다.
페이지네이션 된 게시판에는 URL에 특정 규칙이 있습니다. page=1, number=1 등 페이지를 넘어갈 때 마다 바뀌는 숫자를 파악해야 합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;naver-뉴스-페이지-url-분석하기&quot;&gt;Naver 뉴스 페이지 URL 분석하기&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41453346-5b646e9e-70b0-11e8-82b2-8c1f28041668.png&quot; alt=&quot;image&quot; /&gt;
&lt;a href=&quot;http://land.naver.com/news/field.nhn?page=1&quot;&gt;네이버 부동산 뉴스 페이지&lt;/a&gt;를 크롤링 하려고 합니다. 접속하여 URL 을 확인해보면 맨 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;page=숫자&lt;/code&gt;가 보입니다.
이는, Pagination 으로 현재 몇 번째 페이지를 보여주는지 알려줍니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41453443-c0b7b422-70b0-11e8-823c-5450befa4619.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;첫번째 페이지라서 http://land.naver.com/news/field.nhn?page=1 인겁니다. 우리는 총 세개의 페이지가 있다는 것을 압니다. 하지만 파이썬은 알지 못하므로, 이 사이트가 총 몇번째 페이지까지 Pagination 되어있는지 코드로 알려줘야 합니다. 
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41454046-f9c525fe-70b2-11e8-8afe-a6dbd680a791.png&quot; alt=&quot;image&quot; /&gt;
첫번째 페이지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:1&lt;/code&gt;, 두번째 페이지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:2&lt;/code&gt; 로 규칙적인 Class 를 가지고 있습니다. 그러면 이를 통해 어떻게 Pagination 의 최대값을 파악하는지 알아보도록 합시다.&lt;/p&gt;

&lt;h4 id=&quot;python-코드-작성하기&quot;&gt;Python 코드 작성하기&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'http://land.naver.com/news/field.nhn?page=1'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;우리가 크롤링하려는 페이지가 여러개이므로 동적인 URL 을 입력해줘야 합니다. 그렇기 때문에 변수를 두개 만들어줬습니다.
&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;maximum&lt;/code&gt;은 pagination 의 최대 값입니다. 총 세개가 있다는 것을 우리는 코드를 통해 알려줄 예정입니다.
&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;page&lt;/code&gt;는 현재 지목하고 있는 page 의 pagination 값입니다. Naver 뉴스 페이지로 설명하자면 http://land…page=&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;, http://land…page=&lt;code class=&quot;highlighter-rouge&quot;&gt;3&lt;/code&gt; 같은 유동적인 값 입니다.&lt;/p&gt;

&lt;p&gt;아래는 페이지네이션이 몇번째 까지 있는지 확인하기 위한 소스 입니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;page_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;NP=r:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;총 &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; 개의 페이지가 확인 됬습니다.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;sup style=&quot;color: #878787;&quot;&gt;&lt;br /&gt;
1: while 에 진입하기 위해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;TRUE&lt;/code&gt; 인 &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;을 입력해줬습니다.&lt;br /&gt;
2: page_list 에 &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r: + str(page)&lt;/code&gt; 클래스를 가진 a를 찾아넣습니다. str(page)는 page가 정수형이기 때문에 String 으로 사용하기 위함입니다.&lt;br /&gt;
3: page_list 에 값이 없을 때. 즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:숫자&lt;/code&gt; 가 없는 클래스일때 실행하는 코드입니다. 여기서 &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:숫자&lt;/code&gt; 가 없다는 것은 숫자가 3을 초과했다는 의미가 되겠습니다. 저희가 크롤링하려는 페이지는 총 3개의 페이지네이션을 가지고 있기 때문입니다.&lt;br /&gt;
4: maximum 은 페이지네이션의 최대 값 즉 3이 되야 합니다. page가 한번 더해진 상태로 들어왔기 때문에 1을 빼준겁니다.&lt;br /&gt;
5: maximum 값을 찾았으므로 while 문에서 탈출합니다.&lt;br /&gt;
6: &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:1&lt;/code&gt;클래스가 Naver 뉴스 안에 있음을 확인했으므로 다음 클래스인 &lt;code class=&quot;highlighter-rouge&quot;&gt;NP=r:2&lt;/code&gt;를 확인하기 위해 작성했습니다. 이 코드가 while 문의 마지막이므로 다시 while의 첫번째 코드로 진행합니다. &lt;br /&gt;
7: maximum 가 원하는 값으로 됬는지 확인합니다.
&lt;/sup&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41454046-f9c525fe-70b2-11e8-8afe-a6dbd680a791.png&quot; alt=&quot;image&quot; /&gt;
네이버 부동산 뉴스 페이지는 총 3개의 페이지를 가지고 있습니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41454996-6e8c8ca8-70b6-11e8-8794-5cde8778e547.png&quot; alt=&quot;image&quot; /&gt;
maximum 변수의 값도 3 인게 확인이 됬습니다.&lt;/p&gt;

&lt;p&gt;그러면 크롤링할 준비가 됬습니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;whole_source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page_number&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'http://land.naver.com/news/field.nhn?page='&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;whole_source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;whole_source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;whole_source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;find_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#content &amp;gt; div.section_headline &amp;gt; ul &amp;gt; li &amp;gt; dl &amp;gt; dt &amp;gt; a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;sup style=&quot;color: #878787;&quot;&gt;&lt;br /&gt;
1: whole_source 는 크롤링할 모든 페이지의 HTML 소스를 전부 저장할 변수입니다. 즉, http://land….page=1 부터 http://land….page=3 의 HTML 소스를 저장합니다.&lt;br /&gt;
2: range 함수는 숫자리스트를 만들어줍니다. range(1, maximum+1) 을 함으로써 1부터 maximum 까지의 숫자 리스트가 생성됩니다. 그리고 page_number 은 1부터 더해지면서 maximum 이 될때까지 for 문을 실행하게 됩니다. maximum+1로 해준 이유는 range 는 첫번째 인자 값 1부터, 두번째 인자 값 &lt;code class=&quot;highlighter-rouge&quot;&gt;미만&lt;/code&gt;까지 실행되기 때문입니다.&lt;br /&gt;
5: HTML 소스를 whole_source 에 전부 넣습니다. 그러면 whole_source는 최종적으로 3개의 HTML 소스를 더한게 됩니다.&lt;br /&gt;
7: 뉴스의 제목 선택자를 찾아서 soup.select 했습니다. find_title 은 모든 뉴스의 제목을 가진 list가 됬습니다.&lt;br /&gt;
9: for 문으로 뉴스 제목들을 출력합니다.
&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41455768-450d2060-70b9-11e8-8f56-7a06d05a5fc6.png&quot; alt=&quot;image&quot; /&gt;
첫번째 페이지의 첫번째 뉴스 제목은 ‘송파구 매매 … ‘ 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41455772-480b7a3c-70b9-11e8-8f2d-afae65d94e1b.png&quot; alt=&quot;image&quot; /&gt;
세번째 페이지의 마지막 뉴스 제목은 ‘입주 시작했는데 …’ 입니다.&lt;/p&gt;

&lt;p&gt;그럼 파이썬 파일을 실행해서 비교해 보겠습니다.&lt;/p&gt;
&lt;center&gt;
&lt;script src=&quot;https://asciinema.org/a/JfjWlT86TRHXdeATGmAGmeO0h.js&quot; id=&quot;asciicast-JfjWlT86TRHXdeATGmAGmeO0h&quot; async=&quot;&quot;&gt;&lt;/script&gt;
&lt;/center&gt;
&lt;p&gt;첫번째 크롤링 된 뉴스 제목과 세번째 페이지에있는 마지막 뉴스 제목까지 전부 크롤링 된게 확인됩니다.&lt;/p&gt;

&lt;p&gt;완성했습니다. 다른 게시판들도 비슷한 구조로 크롤링이 가능합니다. 그리고 몇몇 사이트들은 Selenium을 사용해야 됩니다.&lt;/p&gt;

&lt;p&gt;코드에 오류가 있거나 질문이 있다면 댓글로 답변해드리도록 하겠습니다.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/14/python-crawling-pagination-1/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/14/python-crawling-pagination-1/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>jekyll 포스트에 Related Post를 추가하는 방법</title>
        <description>&lt;h2 id=&quot;같은-카테고리의-글-리스팅-하기&quot;&gt;같은 카테고리의 글 리스팅 하기&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;파이썬 강의를 따라하던 사람이 피드백을 해서 개발하게 됬습니다. 아직 디자인은 안했습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;_layoutsposthtml-수정하기&quot;&gt;_layouts/post.html 수정하기&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41375138-1de8ae52-6f90-11e8-81b2-9e9cd66589b3.png&quot; alt=&quot;image&quot; /&gt;
post.html 중간 부분쯤을 보면 &lt;code class=&quot;highlighter-rouge&quot;&gt;content&lt;/code&gt; 가 보입니다. 이 content 부분이 지금 Jekyll에서 포스트를 쓰는 부분입니다. 위에 소스부분을 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;content&lt;/code&gt; 위에 넣든 아래에 넣든 선택하면 됩니다. 포스트 갯수가 너무 많아지면 지저분해질까 싶어서, 페이지네이션도 구현할까 싶습니다. 오늘은 여기까지만 구현했습니다. 소스에 대한 질문이 있으면 언제든 댓글 남겨주시면 설명해드리겠습니다.&lt;/p&gt;

&lt;h4 id=&quot;_sass_basescss-에서-디자인-정하기&quot;&gt;_sass/_base.scss 에서 디자인 정하기&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41375464-2c5d929e-6f91-11e8-9894-a7aa70797812.png&quot; alt=&quot;image&quot; /&gt;
저는 이런식으로 CSS 코드를 작성했는데, 아직 미완성이라 깔끔하진 않네요. 마음대로 커스터마이징해서 추가하시면 됩니다.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/14/how-to-add-jekyll-related-post/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/14/how-to-add-jekyll-related-post/</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 5 : Beautiful Soup와 Selenium을 함께 사용하는 방법</title>
        <description>&lt;h2 id=&quot;selenium으로-진입한-웹-사이트-크롤링하기&quot;&gt;Selenium으로 진입한 웹 사이트 크롤링하기&lt;/h2&gt;

&lt;h4 id=&quot;1-facebook-profile로-접속할-준비하기&quot;&gt;1. Facebook Profile로 접속할 준비하기&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;/2018/06/12/python-crawling-selenium-2/&quot;&gt;파이썬 크롤링 튜토리얼 - 4&lt;/a&gt;에서 페이스북에 로그인 하는 방법을 알아봤었습니다.
튜토리얼 - 4 에서 완성한 코드를 재검토해보고 시작하겠습니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium.webdriver.common.keys&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;아이디&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;패스워드&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/Users/hjvsdh/crawl/chromedriver&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.facebook.org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Facebook&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;email&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pass&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RETURN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;오늘은 이 코드를 응용해서, 내 타임라인에 있는 글을 몇개 긁어와보려고 합니다. 우리가 사용하는 driver 가 profile에 접속할 수 있도록 profile 링크(href)를 찾아줘야하는데, 이전에 사용했던 선택자말고 &lt;code class=&quot;highlighter-rouge&quot;&gt;XPath&lt;/code&gt;를 사용해볼겁니다.&lt;/p&gt;

&lt;p&gt;프로필태그의 href값을 찾기 위해 아래 사진처럼 개발자모드에 들어가서 이 부분을 선택해줍니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41325353-b99e94b6-6ef4-11e8-93ca-59d9ecca5e7c.png&quot; alt=&quot;image&quot; /&gt;
이 부분을 우클릭하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Copy -&amp;gt; Copy XPath&lt;/code&gt;를 해줍니다.&lt;/p&gt;

&lt;p&gt;그리고 4장에서 완성했던 코드 제일 끝에, 아래 코드를 입력합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_elements_by_xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'이곳에 Copy했던 XPath를 붙여넣습니다.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'href'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;driver.find_elements_by_xpath XPath로 해당 elements 를 가져오는 겁니다. 기본적으로 a = find_elements_by_xpath 를 하게되면 a 는 list 상태가 되므로, a[0]을 한 뒤, get_attribute(‘href’)를 하는 겁니다. 그러면 elements 안에 있는 href(프로필 주소) 속성값으로 Web Driver 가 접속하게 되는겁니다.&lt;/p&gt;

&lt;p&gt;이제 내 타임라인에 접근하는 것은 성공했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;만약 XPath를 찾을 수 없다는 에러가 나오면, time 을 import 하여 Facebook 페이지가 원활히 로딩이 끝날때 까지 time.sleep(5)로 5초정도 기다려주면 해결됩니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;import time&lt;/code&gt;을 하고, elem.send_keys(Keys.RETURN)아래에 time.sleep(5)를 씁니다. UI가 로딩될 때 까지 기다리는 방법도 있습니다. &lt;a href=&quot;http://selenium-python.readthedocs.io/waits.html&quot;&gt;참고 문서&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;2-facebook-profile에-있는-데이터-크롤링하기&quot;&gt;2. Facebook Profile에 있는 데이터 크롤링하기&lt;/h4&gt;
&lt;p&gt;페이스북 타임라인 포스트 크롤링같은 경우에는 &lt;a href=&quot;https://developers.facebook.com/docs/graph-api/?locale=ko_KR&quot;&gt;Facebook Graph API&lt;/a&gt;를 사용하는게 훨씬 간결하고 편합니다. 하지만 우리가 크롤링하려는 부분은 바로 이 부분입니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41327261-bc0cfefa-6efd-11e8-9abd-a40bff4114f0.png&quot; alt=&quot;image&quot; /&gt;
좌측에 위치한 소개 부분을 크롤링 할 겁니다. Web Driver 가 현재 실행중인 웹 사이트의 소스를 가져오려면 아래 소스를 입력해야 합니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_source&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;이렇게 req에 소스를 저장했으면 이 req가 HTML parser를 사용해야한다고 알려줘야합니다. &lt;a href=&quot;/2018/06/09/python-crawling-1/&quot;&gt;참고 : 파이썬 크롤링 튜토리얼 - 1&lt;/a&gt;. 그 전에 맨 윗쪽에 &lt;code class=&quot;highlighter-rouge&quot;&gt;from bs4 import BeautifulSoup&lt;/code&gt; 를 해줘야겠죠?&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;그리고 선택자를 찾아내야 합니다. 
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41327433-6a5ebffc-6efe-11e8-93bc-c3c7b554957e.png&quot; alt=&quot;image&quot; /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;Copy -&amp;gt; Copy Selector&lt;/code&gt; 을 하게 되면 div의 id가 하나 나옵니다. 그럼 튜토리얼 - 1 에서 처럼 출력이 되는지 확인하기 위해 코드를 입력해봅시다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;information_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#intro_container_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;information&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;information_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;information&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41327533-d64ed58a-6efe-11e8-8688-5febd0b61725.png&quot; alt=&quot;image&quot; /&gt;
크롤링이 된게 확인이 됩니다!&lt;/p&gt;

&lt;p&gt;최종 소스&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium.webdriver.common.keys&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;아이디&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;패스워드&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/Users/hjvsdh/crawl/chromedriver&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.facebook.org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Facebook&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;email&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pass&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RETURN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_elements_by_xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'//*[@id=&quot;u_0_a&quot;]/div[1]/div[1]/div/a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'href'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_source&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;information_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#intro_container_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;information&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;information_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;information&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

</description>
        <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/13/selenium-with-beautifulsoup-1/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/13/selenium-with-beautifulsoup-1/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 4 : Selenium을 이용해 페이스북에 로그인</title>
        <description>&lt;h2 id=&quot;selenium으로-facebook-로그인하기&quot;&gt;Selenium으로 Facebook 로그인하기&lt;/h2&gt;
&lt;p&gt;&lt;sup style=&quot;color: #878787;&quot;&gt;
    &lt;a href=&quot;/2018/06/09/python-crawling-1/&quot;&gt;Beautiful Soup&lt;/a&gt; 은 1장과 2장에서 다룹니다.
&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-facebook-의-html-분석하기&quot;&gt;1. &lt;a href=&quot;https://www.facebook.com/&quot;&gt;Facebook&lt;/a&gt; 의 HTML 분석하기&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;/2018/06/12/python-crawling-selenium-1/&quot;&gt;파이썬 크롤링 튜토리얼 - 3&lt;/a&gt;의 Selenium으로 검색하기에서 봤듯이, input에 값을 입력하려면 name이나 id같은 &lt;code class=&quot;highlighter-rouge&quot;&gt;선택자&lt;/code&gt;가 필요합니다. 개발자 모드에서 찾아보도록 합시다. 
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41305034-aaec211a-6eac-11e8-9f94-3bf30c9e0eb9.png&quot; alt=&quot;image&quot; /&gt;
아이디를 입력해야 하는 곳은 &lt;code class=&quot;highlighter-rouge&quot;&gt;email&lt;/code&gt;이라는 id를 사용 중입니다.
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41305056-b84dd8b2-6eac-11e8-9098-c73e756f3e5a.png&quot; alt=&quot;image&quot; /&gt;
패스워드를 입력해야 하는 곳은 &lt;code class=&quot;highlighter-rouge&quot;&gt;pass&lt;/code&gt;라는 id를 사용 중입니다.&lt;/p&gt;
&lt;h4 id=&quot;2-python-코드-작성하기&quot;&gt;2. Python 코드 작성하기&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium.webdriver.common.keys&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;아이디&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;패스워드&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;WebDriver의 경로&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.facebook.org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Facebook&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;email&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pass&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Keys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RETURN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;usr과 pwd에는 본인의 페이스북 아이디와 비밀번호를 각각 입력해주면 됩니다.&lt;br /&gt;
driver.get 까지는 &lt;a href=&quot;/2018/06/12/python-crawling-selenium-1/&quot;&gt;파이썬 크롤링 튜토리얼 - 3&lt;/a&gt;에서 다뤘던 내용이라 생략하겠습니다.&lt;br /&gt;&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;assert &quot;Facebook&quot; in driver.title&lt;/code&gt; : driver.title이 Facebook 이 아니면 예외처리를 하여 Error을 내줘! 라는 의미입니다. Facebook 에 접근한건지 아닌지를 판단하기 위해 입력한 코드입니다. &lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;elem = driver.find_element_by_id(&quot;email&quot;)&lt;/code&gt; : 위에서 분석한 아이디 입력란의 id를 찾아서 커서를 두겠다는 의미입니다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;elem.send_keys(usr)&lt;/code&gt; : usr에 입력한 페이스북 아이디 값을 현재 커서가 위치한 곳에 넣겠다는 뜻입니다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;elem = driver.find_element_by_id(&quot;pass&quot;)&lt;/code&gt; : 위에서 분석한 패스워드 입력란의 id를 찾아서 커서를 두겠다는 의미입니다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;elem.send_keys(pwd)&lt;/code&gt; : pwd에 입력한 페이스북 패스워드 값을 현재 커서가 위치한 곳에 넣겠다는 뜻입니다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;elem.send_keys(Keys.RETURN)&lt;/code&gt; : Enter키를 누르게 합니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그리고 py파일을 실행하게 되면, 페이스북에 알아서 로그인 하는 게 보입니다.&lt;/p&gt;

&lt;p&gt;응용하여 Logout 기능까지도 만들어 보면, 이 포스트를 제대로 이해했는지 확인할 수 있을 것 같습니다.&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/12/python-crawling-selenium-2/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/12/python-crawling-selenium-2/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
      <item>
        <title>파이썬 크롤링 튜토리얼 - 3 : Selenium 사용법과 이해</title>
        <description>&lt;h2 id=&quot;selenium으로-크롤링-하기&quot;&gt;Selenium으로 크롤링 하기&lt;/h2&gt;
&lt;p&gt;&lt;sup style=&quot;color: #878787;&quot;&gt;
    &lt;a href=&quot;/2018/06/09/python-crawling-1/&quot;&gt;Beautiful Soup&lt;/a&gt; 은 1장과 2장에서 다룹니다.
&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-selenium-에-대해서&quot;&gt;1. &lt;a href=&quot;https://www.seleniumhq.org/&quot;&gt;Selenium&lt;/a&gt; 에 대해서&lt;/h4&gt;
&lt;p&gt;Selenium은 웹 애플리케이션을 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;테스팅 프레임워크&lt;/code&gt;입니다. 자동화 테스트를 위해 여러 가지 기능을 지원합니다. 다양한 언어에서도 사용이 가능합니다. Beautiful Soap는 웹사이트에서 버튼을 클릭해야 얻을 수 있는 데이터라던가, Javascript 에 조건이 충족되어야만 얻을 수 있는 데이터에 접근하는 것에 한계가 있습니다. 그래서, 직접적으로 웹 사이트에 접근할 수 있게 해주는 Selenium을 사용해야 합니다. 새로운 환경에서 웹 브라우저를 대신해 줄 &lt;a href=&quot;http://chromedriver.chromium.org/downloads&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Web Driver&lt;/code&gt;&lt;/a&gt;가 필요합니다. Web Driver를 눌러 설치를 합시다. Web Driver는 Selenium이 사용할 웹 브라우저이고, Selenium으로 자동화하여 웹 사이트를 탐험하면 됩니다.&lt;/p&gt;

&lt;h4 id=&quot;2-selenium-이해하기&quot;&gt;2. Selenium 이해하기&lt;/h4&gt;
&lt;p&gt;pip 명령어를 사용해 Selenium 을 설치해줍니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt; pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;selenium &lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;Python파일을 하나 만들고 아래 코드를 실행해봅시다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;
 
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Webdriver의 경로를 입력합니다.&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;파일을 실행해보면 어떻게 될까요?
&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41285921-b8616c44-6e78-11e8-95b4-83150949de2a.png&quot; alt=&quot;image&quot; width=&quot;100%&quot; /&gt;
크롬 창이 켜졌습니다! Selenium 으로 제어하기 때문에, 크롬창에 자동화된 테스트 소프트웨어로 제어중이라는겁니다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://www.naver.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;맨 마지막줄에 입력하고, 다시 실행해봅니다. 네이버로 접속되는게 보일겁니다.&lt;/p&gt;

&lt;h4 id=&quot;3-selenium-으로-검색하기&quot;&gt;3. Selenium 으로 검색하기&lt;/h4&gt;
&lt;p&gt;이제 셀레니움으로 크롬을 꺼냈으니 무라도 썰어야합니다. 자, 아래 코드를 입력해봅시다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Webdriver 경로를 입력합니다.&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://google.com/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;q&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;개발새발 블로그&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;실행해보면 구글에 개발새발 블로그가 검색됩니다. 어떤식으로 진행이 되는지 하나하나 알아볼까요?
driver.get()까지는 아까 얘기했으니 그 다음줄부터 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/39974109/41304474-38b9ec2c-6eab-11e8-888d-6ccfaf6a3c77.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;q&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

위 개발자 도구를 확인해보면 우리가 사용할 input의 name이 q 인것을 확인할 수 있습니다. search_box가 커서를 어디다 둬야할 지 name으로 찾아준겁니다.
&lt;/center&gt;

&lt;center&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send_keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;개발새발 블로그&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_box&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

아까 찾은 검색 input 에 개발새발 블로그를 입력하고 submit()으로 검색 버튼을 누른겁니다.

&lt;br /&gt;
&lt;br /&gt;
간단하게 Selenium에 대해 알아봤습니다. 다음 장에서는, Facebook Login을 구현해보도록 하겠습니다.
&lt;/center&gt;
</description>
        <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
        <link>https://l0o02.github.io/2018/06/12/python-crawling-selenium-1/</link>
        <guid isPermaLink="true">https://l0o02.github.io/2018/06/12/python-crawling-selenium-1/</guid>
        
        
        <category>crawl</category>
        
      </item>
    
  </channel>
</rss>
