<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기 | 개발새발 블로그</title>
  <meta name="author" content="dohyun">
  <meta name="description" content="Scrapy Shell 을 통해 개념을 이해하고, 네이버 뉴스 페이지를 크롤링 하여 CSV파일로 내보내기까지 하겠습니다.">
  <meta property="og:title" content="파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기 | 개발새발 블로그">
  <meta property="og:url" content="http://localhost:4000/2018/06/19/python-scrapy-1/">
  <meta property="og:site_name" content="개발새발 블로그">
  <meta property="og:description" content="Scrapy Shell 을 통해 개념을 이해하고, 네이버 뉴스 페이지를 크롤링 하여 CSV파일로 내보내기까지 하겠습니다.">
  <meta property="og:image" content="https://s3.amazonaws.com/thinkific/courses/course_card_image_000/216/1891512778404.original.jpg?1512778404">
  <meta property="og:type" content="blog">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:description" content="Scrapy Shell 을 통해 개념을 이해하고, 네이버 뉴스 페이지를 크롤링 하여 CSV파일로 내보내기까지 하겠습니다.">
  <meta name="twitter:title" content="파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기 | 개발새발 블로그">
  <meta name="twitter:url" content="http://localhost:4000/2018/06/19/python-scrapy-1/">
  <meta name="twitter:site" content="개발새발 블로그">
  <meta name="twitter:creator" content="@DirtyBackend">
  <meta name="twitter:domain" content="http://localhost:4000">
  <meta property="twitter:image" content="https://s3.amazonaws.com/thinkific/courses/course_card_image_000/216/1891512778404.original.jpg?1512778404">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Lora|Space+Mono:700">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="shortcut icon" type="image/x-icon" href="/assets/icon/favicon.ico" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <link rel="alternate" type="application/rss+xml" title="개발새발 블로그" href="http://localhost:4000/feed.xml">
  <link rel="canonical" href="http://localhost:4000/2018/06/19/python-scrapy-1/">
  
  
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-120591017-1', 'auto');
      ga('send', 'pageview');
    </script>
  
</head>


  <body>

    <main>
      <article itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="section-padding--lg mast rellax" data-rellax-speed="-4">
    <a class="nav nav--white" href="/">
      <i class="fa fa-lg fa-arrow-left"></i>
      <span>Back to Posts</span>
    </a>
    <figure class="absolute-bg mast__img" style="background-image: url('https://s3.amazonaws.com/thinkific/courses/course_card_image_000/216/1891512778404.original.jpg?1512778404');"></figure>
    <div class="mast__container">
      <span><time datetime="2018-06-19T00:00:00+09:00" itemprop="datePublished">Jun 19, 2018</time></span>
      <h1 itemprop="name headline">파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기</h1>
      
        <span>Posted in 
          
            <a class="nav--white" href="/category/crawl">crawl</a>
          
        </span>
      
      <span></span>
    </div>
  </header>
<script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script>
<script>addBackToTop()</script>

  <section class="section-padding bg-grey" itemprop="articleBody">
    <div class="post">
      <ul id="markdown-toc">
  <li><a href="#scrapy-란" id="markdown-toc-scrapy-란">Scrapy 란?</a></li>
  <li><a href="#scrapy-첫-코드-작성하기" id="markdown-toc-scrapy-첫-코드-작성하기">Scrapy 첫 코드 작성하기</a>    <ul>
      <li><a href="#설치하기" id="markdown-toc-설치하기">설치하기</a></li>
      <li><a href="#scrapy-shell-사용해보기" id="markdown-toc-scrapy-shell-사용해보기">Scrapy Shell 사용해보기</a></li>
      <li><a href="#제목" id="markdown-toc-제목">제목</a></li>
      <li><a href="#올린-뉴스-사이트" id="markdown-toc-올린-뉴스-사이트">올린 뉴스 사이트</a></li>
      <li><a href="#미리보기" id="markdown-toc-미리보기">미리보기</a></li>
    </ul>
  </li>
  <li><a href="#spider-작성하기" id="markdown-toc-spider-작성하기">Spider 작성하기</a>    <ul>
      <li><a href="#hello-scrapy-world" id="markdown-toc-hello-scrapy-world">Hello Scrapy World!</a></li>
      <li><a href="#spider-생성하기" id="markdown-toc-spider-생성하기">Spider 생성하기</a></li>
      <li><a href="#spider-실행하고-결과-확인하기" id="markdown-toc-spider-실행하고-결과-확인하기">Spider 실행하고 결과 확인하기</a></li>
    </ul>
  </li>
  <li><a href="#csv로-내보내기" id="markdown-toc-csv로-내보내기">CSV로 내보내기</a></li>
</ul>
<h2 id="scrapy-란">Scrapy 란?</h2>
<p>최근 웹에는 수억개의 웹페이지가 있으며, 대부분의 페이지들은 수많은 정보를 가지고 있습니다. 최근 빅데이터가 대두되면서 이전에 작성되었던 페이지들의 정보를 모아 유의미한 정보를 도출하기 위한 여러가지 방법들이 논의되고 있고, 이를 Scraping(혹은 Crawling)이라고 합니다. <code class="highlighter-rouge">Scrapy</code>는 Scraping을 도와주기위한 파이썬 기반 라이브러리입니다. Scrapy를 이용하여 필요한 페이지로 접속하여 원하는 형태로 데이터를 가공하여 데이터를 저장할수 있도록 도와줍니다. <a href="http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC/Scrapy#h_a103e753e7b14159b61f918a62b1a4c5">(출처)</a></p>

<h2 id="scrapy-첫-코드-작성하기">Scrapy 첫 코드 작성하기</h2>
<h4 id="설치하기">설치하기</h4>
<p>터미널에 아래 명령어를 입력해 <code class="highlighter-rouge">Scrapy</code>를 설치합니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">pip <span class="nb">install </span>scrapy</code></pre>
</figure>

<h4 id="scrapy-shell-사용해보기">Scrapy Shell 사용해보기</h4>
<p>Scrapy Shell을 사용함으로써, 프로젝트를 생성하지 않고 간단하게 Scrapy를 체험할 수 있습니다. 아래 명령어를 입력해서 Shell을 실행시킵니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">scrapy shell</code></pre>
</figure>

<p><a href="http://news.naver.com/main/list.nhn?mode=LSD&amp;mid=sec&amp;sid1=001">네이버 뉴스 페이지</a>를 크롤링하려고 합니다. Scrapy 크롤러는 <code class="highlighter-rouge">starting point</code>를 필요로 합니다. 말 그대로, 크롤링을 시작할 위치를 정하는 겁니다. 
아래 명령어를 통해 Starting Point를 설정합시다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">fetch</span><span class="p">(</span><span class="s">'http://news.naver.com/main/list.nhn?mode=LSD&amp;mid=sec&amp;sid1=001'</span><span class="p">)</span></code></pre>
</figure>

<p>그럼, <a href="https://ko.wikipedia.org/wiki/HTTP_%EC%83%81%ED%83%9C_%EC%BD%94%EB%93%9C">Response Code</a>가 출력됩니다.
<img src="https://user-images.githubusercontent.com/39974109/41637651-ef34b3a8-748f-11e8-9bcc-e4c4e1fadd78.png" alt="image" />
이제 크롤러가 무엇을 다운로드했는지 확인해봅시다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">view</span><span class="p">(</span><span class="n">response</span><span class="p">)</span></code></pre>
</figure>

<p>이 명령어는 크롤러가 다운로드한 페이지를 기본 브라우저를 통해 실행합니다.
<img src="https://user-images.githubusercontent.com/39974109/41637767-863f6f04-7490-11e8-981f-7b06810d10e3.png" alt="image" />
경로를 보면 아시겠지만, 로컬에 저장이 됬습니다. 이제 소스를 확인해볼겁니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span></code></pre>
</figure>

<p>다운로드 된, 웹 사이트의 소스가 출력됩니다.
<img src="https://user-images.githubusercontent.com/39974109/41637816-d7a9ecfc-7490-11e8-81a0-929fc60d8fb7.png" alt="image" />
오늘 크롤링 할 것은 세 가지 입니다.</p>
<ul>
  <li>제목</li>
  <li>올린 뉴스 사이트</li>
  <li>미리보기</li>
</ul>

<h4 id="제목">제목</h4>
<p>그러면 제목을 먼저 크롤링 해보겠습니다. 개발자 도구에 들어가서 제목 부분의 <code class="highlighter-rouge">XPath</code>를 복사합니다. 두번째 뉴스의 XPath와 맨 아랫줄에있는 뉴스의 XPath도 비교해봅니다.</p>
<ol>
  <li>첫번째 뉴스 : //*[@id=”main_content”]/div[2]/ul[1]/li[1]/dl/dt[2]/a</li>
  <li>두번째 뉴스 : //*[@id=”main_content”]/div[2]/ul[1]/li[2]/dl/dt[2]/a</li>
  <li>마지막 뉴스 : //*[@id=”main_content”]/div[2]/ul[2]/li[10]/dl/dt[2]/a</li>
</ol>

<p>여기서 어떤 정보를 얻을 수 있을까요?<br /><br />
첫번째로는, 포스트는 <code class="highlighter-rouge">li[1]~li[10]</code>로 구성됬다는 것 입니다.<br />
두번째로는, ul로 <code class="highlighter-rouge">두 파트</code>가 나뉜다는 것 입니다. <em>아래 사진 참고.</em>
<img src="https://user-images.githubusercontent.com/39974109/41638191-08538ef6-7493-11e8-808e-9f0dc4bc541d.png" alt="image" /></p>

<p>결국 모든 포스트를 list에 저장하기 위해서는 태그[숫자]의 숫자 부분을 삭제해주면 됩니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="o">//*</span><span class="p">[</span><span class="nd">@id</span><span class="o">=</span><span class="s">"main_content"</span><span class="p">]</span><span class="o">/</span><span class="n">div</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="n">ul</span><span class="o">/</span><span class="n">li</span><span class="o">/</span><span class="n">dl</span><span class="o">/</span><span class="n">dt</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="n">a</span><span class="o">/</span></code></pre>
</figure>

<p>XPath를 얻었으니 이제 크롤링을 해봅니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//*[@id="main_content"]/div[2]/ul/li/dl/dt[2]/a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span></code></pre>
</figure>

<p><img src="https://user-images.githubusercontent.com/39974109/41638554-f403c9be-7494-11e8-9911-afc5729e7de0.png" alt="image" />
포스트 제목들이 출력됩니다. \n\t\r 이 지저분해 보이지만, 이 부분은 다음에 Project를 생성하고 CSV를 만들어 내보낼 때 제거하도록 합시다.</p>
<h4 id="올린-뉴스-사이트">올린 뉴스 사이트</h4>
<p>올린 뉴스 사이트는 CSS Selector를 통해 크롤링 했습니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.writing::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span></code></pre>
</figure>

<p>뉴스 회사들이 출력되는게 보일겁니다.</p>
<h4 id="미리보기">미리보기</h4>
<p>미리보기도 마찬가지로 CSS Selector를 통해 크롤링 했습니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.lede::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span></code></pre>
</figure>

<blockquote>
  <p>계속 CSS Selector인 Class로 크롤링 하는 이유는 .writing이나 .lede같은 의미가 있는 Class들은 대체로 같은 요소에만 쓰입니다. 꼭 그런것만은 아니니 결과를 꼭 확인해 봐야 합니다. 확인해 봤을 때 같은 요소에서만 쓰인다면, 훨씬 간결하고 유연한 코드를 완성할 수 있습니다.</p>
</blockquote>

<h2 id="spider-작성하기">Spider 작성하기</h2>
<p>기본적인 scrapy 프로젝트의 구조는 이렇습니다. 참고하고 프로젝트를 만들어봅시다.
<img src="https://user-images.githubusercontent.com/39974109/41639378-76caee9c-7498-11e8-8499-480f2b8c34bc.png" alt="image" /></p>
<h4 id="hello-scrapy-world">Hello Scrapy World!</h4>
<p>아래 명령어를 통해 <code class="highlighter-rouge">scrapy project</code>를 생성해줍니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">scrapy startproject naverscraper</code></pre>
</figure>

<p>그리고 프로젝트 안에 있는 <code class="highlighter-rouge">spiders</code>폴더에 들어갑니다.</p>
<center>
<script src="https://asciinema.org/a/Ix2l2BBFNMq08ajIueRefzaan.js" id="asciicast-Ix2l2BBFNMq08ajIueRefzaan" async=""></script>
</center>

<h4 id="spider-생성하기">Spider 생성하기</h4>
<p>genspider 명령어를 통해서 <code class="highlighter-rouge">newsbot</code>을 생성합니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">scrapy genspider newsbot news.naver.com/main/list.nhn?mode<span class="o">=</span>LSD&amp;mid<span class="o">=</span>sec&amp;sid1<span class="o">=</span>001</code></pre>
</figure>

<p>생성된 <code class="highlighter-rouge">newsbot.py</code> 에 소스를 입력합니다.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">NewsbotSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
	<span class="n">name</span> <span class="o">=</span> <span class="s">'newsbot'</span>
	<span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://news.naver.com/main/list.nhn?mode=LSD&amp;mid=sec&amp;sid1=001'</span><span class="p">]</span>

	<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
		<span class="n">titles</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//*[@id="main_content"]/div[2]/ul/li/dl/dt[2]/a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
		<span class="n">authors</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.writing::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
		<span class="n">previews</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.lede::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

		<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">titles</span><span class="p">,</span> <span class="n">authors</span><span class="p">,</span> <span class="n">previews</span><span class="p">):</span>
			<span class="n">scraped_info</span> <span class="o">=</span> <span class="p">{</span>
				<span class="s">'title'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
				<span class="s">'author'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
				<span class="s">'preview'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
			<span class="p">}</span>
			<span class="k">yield</span> <span class="n">scraped_info</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p><sup style="color: #878787;">
8~10: 크롤링 한 데이터를 list로 저장<br />
12: zip 함수는 아래 사진 참고<br />
13: scraped_info 에 zip으로 slice 한 데이터들을 저장<br />
14~16: strip 함수를 이용해 문자열에 필요없는 공백을 제거<br />
</sup>
<img src="https://user-images.githubusercontent.com/39974109/41640142-a3ddbef2-749b-11e8-9e73-43fc69118fb2.png" alt="image" /></p>

<h4 id="spider-실행하고-결과-확인하기">Spider 실행하고 결과 확인하기</h4>
<p>newsbot을 실행시켜봅니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">scrapy crawl newsbot</code></pre>
</figure>

<p><img src="https://user-images.githubusercontent.com/39974109/41640256-0ba7dc20-749c-11e8-8b24-8bb077b558f0.png" alt="image" /></p>

<h2 id="csv로-내보내기">CSV로 내보내기</h2>
<p>프로젝트 폴더에있는 <code class="highlighter-rouge">settings.py</code>에 입력합니다:</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="n">FEED_FORMAT</span> <span class="o">=</span> <span class="s">"csv"</span>
<span class="n">FEED_URI</span> <span class="o">=</span> <span class="s">"naver_news.csv"</span></code></pre>
</figure>

<p>그리고 다시 Spider을 실행합니다.</p>

<figure class="highlight">
  <pre><code class="language-bash" data-lang="bash">scrapy crawl newsbot</code></pre>
</figure>

<p>그럼 같은 디렉토리에 뉴스 내용들이 크롤링되어 csv에 저장됩니다.
<img src="https://user-images.githubusercontent.com/39974109/41640344-64582b7c-749c-11e8-9510-b57a0356ec58.png" alt="image" /></p>

<p>최종 소스 :<br />
<code class="highlighter-rouge">newsbot.py</code></p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">NewsbotSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
	<span class="n">name</span> <span class="o">=</span> <span class="s">'newsbot'</span>
	<span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://news.naver.com/main/list.nhn?mode=LSD&amp;mid=sec&amp;sid1=001'</span><span class="p">]</span>

	<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
		<span class="n">titles</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//*[@id="main_content"]/div[2]/ul/li/dl/dt[2]/a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
		<span class="n">authors</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.writing::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
		<span class="n">previews</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.lede::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

		<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">titles</span><span class="p">,</span> <span class="n">authors</span><span class="p">,</span> <span class="n">previews</span><span class="p">):</span>
			<span class="n">scraped_info</span> <span class="o">=</span> <span class="p">{</span>
				<span class="s">'title'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
				<span class="s">'author'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
				<span class="s">'preview'</span> <span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
			<span class="p">}</span>
			<span class="k">yield</span> <span class="n">scraped_info</span></code></pre>
</figure>

<p>수고하셨습니다, 이것으로 scrapy의 기본적인 사용방법에 대해 알아봤습니다.</p>

      <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <!-- In Post -->
      <ins class="adsbygoogle"
          style="display:inline-block;width:970px;height:250px"
          data-ad-client="ca-pub-2563278096701182"
          data-ad-slot="6770932881"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      <div id="share-bar">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
        <div class="share-buttons">
            <a  href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2018/06/19/python-scrapy-1/"
                onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
                title="Share on Facebook">
                <i class="fa fa-facebook-official share-button"> facebook</i>
            </a>
    
            <a  href="https://twitter.com/intent/tweet?text=파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기&url=http://localhost:4000/2018/06/19/python-scrapy-1/"
                onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
                title="Share on Twitter">
                <i class="fa fa-twitter share-button"> twitter</i>
            </a>
    
            <a  href="https://plus.google.com/share?url=http://localhost:4000/2018/06/19/python-scrapy-1/"
                onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
                title="Share on Google+" >
                <i class="fa fa-google-plus share-button"> google</i>
            </a>

            <a  href="https://www.buymeacoffee.com/vWEIGz71S"
                onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
                title="Buy me a coffee" >
                <i class="fa fas fa-coffee share-button"> buy me a coffee</i>
            </a>
        </div>
    
</div>
      <div class="category-box">
        <span class="related">RELATED POST</span>
        
          

              
                <li class="post-list"><a href="/2018/06/09/python-crawling-1/">- 파이썬 크롤링 튜토리얼 - 1 : Beautiful Soup의 개념과 사용법</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/10/python-crawling-2/">- 파이썬 크롤링 튜토리얼 - 2 : Beautiful Soup로 네이버 실시간 검색어 크롤링</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/12/python-crawling-selenium-1/">- 파이썬 크롤링 튜토리얼 - 3 : Selenium 사용법과 이해</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/12/python-crawling-selenium-2/">- 파이썬 크롤링 튜토리얼 - 4 : Selenium을 이용해 페이스북에 로그인</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/13/selenium-with-beautifulsoup-1/">- 파이썬 크롤링 튜토리얼 - 5 : Beautiful Soup와 Selenium을 함께 사용하는 방법</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/14/python-crawling-pagination-1/">- 파이썬 크롤링 튜토리얼 - 6 : Pagination 된 게시판 크롤링</a></li>
              
            
          

              
                <li class="post-list"><a href="/2018/06/15/python-crawling-scrapy/">- 파이썬 크롤링 튜토리얼 - 7 : Scrapy 란? Scrapy VS Beautiful Soup</a></li>
              
            
          

              
                <li class="post-list-selected">- 파이썬 크롤링 튜토리얼 - 8 : Scrapy 사용법, 네이버 뉴스 크롤링해서 CSV로 내보내기</li>
              
            
          
        
</div>
      <div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://l0o02-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </section>
</article>


  <section class="next">
    <a class="next__link" href="/2018/06/22/html-back-to-top/" style="background-image: url('https://static1.squarespace.com/static/535522c9e4b0ecf5755f4156/56edbc8b3c44d88f013be256/588c92f403596e0fcbb7d87f/1516124678330/back-to-top-1500.jpg?format=1500w');">
      <div class="next__container">
        <span>Read Next</span>
        <h2>웹 페이지에 맨 위로 이동하는 버튼을 만들어주는 라이브러리</h2>
      </div>
    </a>
  </section>


    </main>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/rellax/1.0.0/rellax.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.min.js"></script>
<script type="text/javascript" src="/assets/js/app.js"></script>
<div id="breadcrumbs" style="display:none;">
        
        <a href="/">Home</a>
        
          
            / <a href="/2018/">2018</a>
          
        
          
            / <a href="/2018/06/">06</a>
          
        
          
            / <a href="/2018/06/19/">19</a>
          
        
          
            / Python scrapy 1
          
        
</div>

  </body>

</html>
